{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is this notebook about?\n",
    "- This notebook shows how to use ChatGPT API for inference, \n",
    "- It also shows how to print real number of tokens used, how to estimate number of tokens & calculcate pricing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "api_key = os.getenv('sk')\n",
    "client = OpenAI(\n",
    "  api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are an AI assistant.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Respond with 'Hello' if you got this message\"\n",
    "    }\n",
    "  ],\n",
    "  #temperature=1,\n",
    "  #max_tokens=256,\n",
    "  #top_p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response:\n",
      "Hello!\n",
      "Processed response\n",
      "['hello!']\n"
     ]
    }
   ],
   "source": [
    "response_text = response.choices[0].message.content.strip()\n",
    "print(\"Raw response:\")\n",
    "print(response_text)\n",
    "\n",
    "response_text = response_text.lower().split('\\n')\n",
    "print(\"Processed response\")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "CompletionUsage(completion_tokens=3, prompt_tokens=27, total_tokens=30, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "total tokens = 30 (prompt_tokens=27, completion_tokens=3)\n"
     ]
    }
   ],
   "source": [
    "# Real number of tokens\n",
    "\n",
    "print(\"Usage:\")\n",
    "print(response.usage)\n",
    "print(f\"total tokens = {response.usage.total_tokens} (prompt_tokens={response.usage.prompt_tokens}, completion_tokens={response.usage.completion_tokens})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "13\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# Estimate number of tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "  if 1: #model == \"gpt-3.5-turbo-0613\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\"\"\")\n",
    "\n",
    "# Example 1\n",
    "prompt = \"tiktoken is great!\"\n",
    "num_tokens = num_tokens_from_string(prompt, \"o200k_base\")\n",
    "print(num_tokens)\n",
    "\n",
    "# Example 2\n",
    "prompt = \"tiktoken is great!\"\n",
    "messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "num_tokens = num_tokens_from_messages(messages, \"gpt-4o\")\n",
    "print(num_tokens)\n",
    "\n",
    "# Example 3\n",
    "prompt = \"Respond with 'Hello' if you got this message\"\n",
    "messages=[\n",
    "{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an AI assistant.\"\n",
    "},\n",
    "{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": prompt\n",
    "}\n",
    "]\n",
    "num_tokens = num_tokens_from_messages(messages, \"gpt-4o-mini\")\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Pricing on 09/05/2025:\n",
    "\n",
    "# gpt-4o: \n",
    "# Input (prompt):\n",
    "# $2.50/1M tokens => 1000 tokens: 0.25 cents\n",
    "# Output (completion):\n",
    "# $10.00/1M tokens => 1000 tokens: 1 cent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "> https://platform.openai.com/docs/overview  \n",
    "> https://platform.openai.com/docs/api-reference/chat/create  \n",
    "> https://platform.openai.com/docs/advanced-usage   \n",
    "> https://platform.openai.com/docs/pricing  \n",
    "> https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
